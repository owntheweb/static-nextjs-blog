---
title: 'The Life and Death of HotSpark the Robot'
type: Blog
date: '2023-06-14'
previewImage: /images/hotspark-the-robot.jpg
tags:
  - Raspberry Pi
  - Python
  - JavaScript
  - electronics
  - robotics
  - Docker
  - balena
  - AWS
  - Lex
  - Polly
  - MongoDB
  - React
  - life
  - TypeScript
embeddedContent:
  title: 'The Pi Cast: Windows 11 on Pi, Cohosting Robot, Voice Assistants'
  height: 378
  url: https://www.youtube-nocookie.com/embed/ofOiv-f-GeA?start=3
---
Posting a short video of my robot dancing to a modified woodchuck song on Reddit resulted in viral reach within the Raspberry Pi community (2021). I was quickly invited to be guest on [tom's HARDWARE Pi Cast](https://www.youtube-nocookie.com/embed/ofOiv-f-GeA?start=3) to talk about the bot, a personal highlight of the year!

This occurred in the latter part of the Covid pandemic, when people were just starting to get out more with others, maybe just before that. I was bucking social isolation in my own geeky way, brainstorming ways to connect with and inspire others online, also delving deeper into electronics/robotics hobbies on my bucket list. I was working to get comfortable on camera, a part of a new job in video communications. Smash that all together and you get a Twitch steam with a robotic co-host named HotSpark. ðŸ¤–

![image](/images/hotspark-the-robot.jpg)

HotSpark was built using a Raspberry Pi 4 and electronic components mostly found at [Adafruit](https://adafruit.com). The robot was held together with the finest pop sickle sticks, hot glue and hobby wire, garnished with servo horn "sprockets". It had five servos; one to pivot, two for the arms and two for the eyes that allowed for fun facial expressions. NeoPixels were used for the mouth and eyes. It was housed in a crafting crate lined with a green screen so that it could be transported to other scenes on video.

![image](/images/hotspark-connections.jpg)

The bot was deployed via [balena](https://www.balena.io/), helping a lot with dev efficiency, monitoring and security. It hosted three docker containers.

A Node.js express server delivered and connected to a robot control UI and [Open Broadcaster Software (OBS)](https://obsproject.com/) layers (robot audio player, bot captions), Twitch API, StreamElements API, Pledge.to API and AWS. It offered a socket.io server for event handling/delivery. It connected to AWS IoT Core, sending messages via MQTT to convert text to speech with mouth movement data via Amazon Polly. Through IoT Core it also sent Twitch chat messages that the bot itself didn't understand to Amazon Lex, identifying a number of message topics for accurate robot responses live.

A MongoDB server generally served as a cache for conversations. It kept data to help prevent chat abuse and annoy factor. For example, it would keep track of last chat by a user so not to respond too quickly if lots of chat was happening at once. My hope here was to keep track of conversations per user so that the robot could keep conversation context over time. With a small stream audience, I didn't prioritize this or develop in this area much.

A Python/CircuitPython server controlled the hardware. There was a lot of excellent support for controlling any hardware I came across with Python, especially around Adafruit products I was using. It hosted a socket.io server that listened for instruction from the Node.js server and a browser window where audio played, triggering timed bot animations.

![image](/images/hotspark-ui.jpg)

*Fancy tablet image generated by Midjourney. 8-bit UI generated by me.*

The React UI offered two tabs. The *Say* tab allowed me to press categories of quick responses, stories and jokes. One example, being "Hello". That triggered one of 30 random hello messages to be spoken by the bot. Think of it as a ventriloquist act without having to worry about the bot's voice. The *Script* tab offered a way to hold pre-scripted conversations for introductions. 

![HotSpark Twitch stream camera setup](/images/hotspark-camera-obs.jpg)

HotSpark was filmed with a Raspberry Pi 3B+, using [custom shared software](https://github.com/owntheweb/raspberry-pi-udp-camera) I created, combining balena, a Pi camera and gstreamer to stream video from the Pi to OBS where live streams were broadcast.

![image](/images/hotspark-wiring.jpg)

The wiring was "simple". At the time of wiring, it was not. ;) It's amazing what a person can learn with little experience. A mind blowing lesson I had learned after assembly was that the wiring was setup much like another dancing banana robot that had a Twitch stream. That bot nearly caught on fire due to poor electrical connections that melted while its creator was away from home. I had this same setup (yet never left the bot unattended)! Check out [this case study](https://www.youtube.com/watch?v=bJ5ppf0po3k&ab_channel=UselessDuckCompany) for info on that, yet also super good insight on thwarting abusive chat users, very impressive work.

I feel the hardest part in getting this working was the Python programming. Servo speed, orientation and motion range had to be accessible outside of Python with a socket.io client listening for instructions. I added a bit of motion math to ease/"tween" between points, otherwise the powerful servos (overkill for pop sickle sticks) had a tendency to rip things apart. Some work had to be done to get NeoPixels functioning at a different voltage than the Raspberry Pi logic. It was all challenging, and FUN.

![image](/images/hotspark-performs.jpg)

I enjoyed making a robot and playing with streaming tech. I gained a lot around getting comfortable on camera. The streamer community was fun. The stream had a growing following of streamers (cool robot co-host tech does that). The project has inspired at least a couple of people to get into engineering with amazing feedback (best part!). With all that however, my time of streaming on Twitch ended quickly.

Preparing content and to be social for streams just flat out drained my energy. By the time a stream started, I felt like a robot (the robot was more lively). It could have improved with time, yet it was more fruitful just connecting with local gurus over zoom and eventually in person. Perhaps it would be fun to try a stream or YouTube channel where it's "just the bot"?

HotSpark retired to raise money for charity. Near Christmas it resided in the living room window, accepting donations for [Springs Rescue Mission](https://www.springsrescuemission.org/) via QR code to a Pledge landing page. I recoded and choreographed [multiple thank you songs](https://soundcloud.com/owntheweb/sets/animatronic-donation-thank-you-songs) that would get triggered by a donation. A relay was added to control holiday lights with the music, just like those cool full home light shows, limited to a smaller space. It actually did pretty well for just sitting in a window.

![image](/images/hotspark-rust-in-peace.jpg)

And then, I killed HotSpark by accidentally applying the wrong voltage to its NeoPixels at a maker event... ðŸ˜­  

THE END

Or is it...

![image](/images/hotspark2-arms.jpg)

Two makerspaces have shown interest in having a charismatic robot enhance (and even represent) their space. With that in mind, I've been applying very mild energy towards a new robot design made from acrylic layers and metal braces.

I like the idea of building a more sturdy bot. Younger kids went crazy with HotSpark (my daughter included, wanted to play football with it outside at first speech) and it seems like a good inspiration tool. I hope to get kids, especially my daughter, excited by STEM education and creative possibilities. Also, my coworkers need more annoying robot video messages.

The next robot I'll make will NOT contain any hot glue, pop sickle sticks or hobby wire. ðŸ¤–